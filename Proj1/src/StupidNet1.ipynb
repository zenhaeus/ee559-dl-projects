{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StupidNet1\n",
    "StupidNet1 applies a convolutional layer and then a fully connected layer to both channels of the input data to predict the binary target. This is done without any auxiliary losses based on the digit classes of the two channels. With the current architecture we can clearly see overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    mu, std = data[0].mean(), data[0].std()\n",
    "    \n",
    "    data[0].sub_(mu).div_(std)\n",
    "    data[3].sub_(mu).div_(std)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_data = prologue.generate_pair_sets(1000)\n",
    "pair_data = normalize_data(pair_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StupidNet1(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(StupidNet1, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(2, 32, kernel_size=3),         # 32 x 12 x 12\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=3),   # 32 x 4 x 4\n",
    "            nn.Conv2d(32, 64, kernel_size=3),        # 64 x 2 x 2\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64 * 2 * 2, nb_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(nb_hidden, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, 64 * 2 * 2)\n",
    "        x = self.classifier(x)\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-1)\n",
    "    nb_epochs = 100\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss = sum_loss + loss.item()\n",
    "        print(e, sum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, data_input, data_target):\n",
    "\n",
    "    nb_data_errors = 0\n",
    "\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        output = model(data_input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = torch.max(output, 1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if data_target.data[b + k] != predicted_classes[k]:\n",
    "                nb_data_errors = nb_data_errors + 1\n",
    "\n",
    "    return nb_data_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stupidNet1 = StupidNet1(100);\n",
    "\n",
    "mini_batch_size = 100;\n",
    "\n",
    "train_model(stupidNet1, pair_data[0], pair_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_errors = compute_nb_errors(stupidNet1, pair_data[0], pair_data[1])\n",
    "nb_test_errors = compute_nb_errors(stupidNet1, pair_data[3], pair_data[4])\n",
    "print('train error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / pair_data[0].size(0),\n",
    "                                                  nb_train_errors, pair_data[0].size(0)))\n",
    "print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / pair_data[4].size(0),\n",
    "                                              nb_test_errors, pair_data[4].size(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
